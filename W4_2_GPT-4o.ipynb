{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##**과제**: 수능 국어 문제 GPT-4로 풀어보기\n",
        "\n",
        "\n",
        "\n",
        "Dataset Download: https://github.com/NomaDamas/KICE_slayer_AI_Korean\n",
        "\n",
        "github의 data > 2023_11_KICE.json data를 colab으로 불러옵니다.\n",
        "\n",
        "요구사항: https://www.notion.so/teamsparta/4-GPT-4-1712dc3ef514808cb792d55f5a09186e\n",
        "\n"
      ],
      "metadata": {
        "id": "jLtm0Midb_pi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import"
      ],
      "metadata": {
        "id": "kwX7OxtQTxzz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import json\n",
        "import requests\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "aASdkI8Vz8tg"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gpt_model=\"gpt-4o\"\n",
        "temperature = 0.5  # 각 token을 샘플링할 때 사용하는 temperature 값입니다.\n",
        "max_tokens = 4096  # 생성하는 최대 token 개수 입니다.\n",
        "frequency_penalty = 0.0  # 같은 단어가 반복적으로 나오는 것을 방지하기 위한 옵션입니다.\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "hoPraglb4Jn4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d82a493e-8dc8-444f-ff8e-5dff9ff1440d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Gather GPT-4  API Info\n",
        "\n",
        "Colab 에서 GPT API 파일 저장하고 가져오기 ( os 환경변수, 로컬경로 등 업로드가 다 않되는 상황에서 취한 방식)"
      ],
      "metadata": {
        "id": "bL3B6i9c0qkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "for filename in uploaded.keys():\n",
        "    print(f\" {filename} is uploaded\")\n",
        "\n",
        "with open('OpenAI_APIKey.txt', 'r') as file:\n",
        "    content = file.read()"
      ],
      "metadata": {
        "id": "iN-YLoZL0LPc",
        "outputId": "9432ede7-0808-42da-84b0-28e0395e341c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 94
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-da515c77-6cf6-4d8d-bad6-13d84911d96a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-da515c77-6cf6-4d8d-bad6-13d84911d96a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving OpenAI_APIKey.txt to OpenAI_APIKey.txt\n",
            " OpenAI_APIKey.txt is uploaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(content)"
      ],
      "metadata": {
        "id": "jKZYUNAv0byS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = content"
      ],
      "metadata": {
        "id": "GpSAdd6C3mt3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##함수: prediction(problem)"
      ],
      "metadata": {
        "id": "626ddOdcDy-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def prediction(problem):\n",
        "    completion = openai.chat.completions.create(\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant for solving Korean exam problems.\"},\n",
        "            {\"role\": \"user\", \"content\": problem}\n",
        "        ],\n",
        "        model=gpt_model,\n",
        "        response_format={\"type\": \"json_object\"},\n",
        "    )\n",
        "    return completion\n"
      ],
      "metadata": {
        "id": "sRY4XLX33qON"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##API access test"
      ],
      "metadata": {
        "id": "217f-AClDoE5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# GPT 출력 테스트\n",
        "problem_text = \"Example question: What is the correct answer for this Korean problem?  output format: json\"\n",
        "result = prediction(problem_text)\n",
        "\n",
        "if result:\n",
        "    print(f\"GPT-4 Prediction: {result}\")\n",
        "else:\n",
        "    print(\"Failed to get a prediction.\")"
      ],
      "metadata": {
        "id": "OUSn1n2D5M7V",
        "outputId": "8e6f6276-2b36-4a10-9256-1de8bcef8aab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPT-4 Prediction: ChatCompletion(id='chatcmpl-AnbCUeMkJkU8P3v9B8FQxIjKF23GU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='{\"answer\": \"C\"}', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1736384434, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_b7d65f1a5b', usage=CompletionUsage(completion_tokens=7, prompt_tokens=39, total_tokens=46, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_content = result.choices[0].message.content\n",
        "fruit_data = json.loads(response_content)\n",
        "\n",
        "formatted_json = json.dumps(fruit_data, indent=4, ensure_ascii=False)\n",
        "print(formatted_json)"
      ],
      "metadata": {
        "id": "7HTjpVAx0ewP",
        "outputId": "84b7ec08-50a0-45d8-9995-88a72ed3a9b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"answer\": \"The correct answer is [insert answer here]\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data upload"
      ],
      "metadata": {
        "id": "LPn80JRSBGAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://raw.githubusercontent.com/NomaDamas/KICE_slayer_AI_Korean/master/data/2023_11_KICE.json'\n",
        "response = requests.get(url)\n",
        "data = response.json()"
      ],
      "metadata": {
        "id": "dRe10sA5AsKk"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(data)\n",
        "print(df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Q0bkmTEbAvKK",
        "outputId": "cdeb7a3a-d3f0-47a5-eb8a-606b87b2287a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   id                                          paragraph  \\\n",
            "0    2023_11_KICE_1-3  사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 ...   \n",
            "1    2023_11_KICE_4-9  (가)[A](중국에서 비롯된 유서(類書)는 고금의 서적에서 자료를 수집하고 항목별로...   \n",
            "2  2023_11_KICE_10-13  법령의 조문은 대개 ‘A에 해당하면 B를 해야 한다.’처럼 요건과효과로 구성된 조건...   \n",
            "3  2023_11_KICE_14-17  하루에 필요한 에너지의 양은 하루 동안의 총 열량 소모량인 대사량으로 구한다. 그중...   \n",
            "4  2023_11_KICE_18-21  혼례를 마친 후 최척이 아내와 함께 장모를 모시고 집으로 돌아오매 하인들이 기뻐했다...   \n",
            "\n",
            "   type                                           problems  \n",
            "0     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "1     0  [{'question': '(가)와 (나)에 대한 설명으로 가장 적절한 것은?', ...  \n",
            "2     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "3     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "4     1  [{'question': '윗글에 대한 설명으로 가장 적절한 것은?', 'choic...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dftest = df.copy()\n",
        "print(dftest.head())"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8t9mte-hzP0-",
        "outputId": "9fbe3741-8137-448d-99b3-125cb23ea9c2"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   id                                          paragraph  \\\n",
            "0    2023_11_KICE_1-3  사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 ...   \n",
            "1    2023_11_KICE_4-9  (가)[A](중국에서 비롯된 유서(類書)는 고금의 서적에서 자료를 수집하고 항목별로...   \n",
            "2  2023_11_KICE_10-13  법령의 조문은 대개 ‘A에 해당하면 B를 해야 한다.’처럼 요건과효과로 구성된 조건...   \n",
            "3  2023_11_KICE_14-17  하루에 필요한 에너지의 양은 하루 동안의 총 열량 소모량인 대사량으로 구한다. 그중...   \n",
            "4  2023_11_KICE_18-21  혼례를 마친 후 최척이 아내와 함께 장모를 모시고 집으로 돌아오매 하인들이 기뻐했다...   \n",
            "\n",
            "   type                                           problems  \n",
            "0     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "1     0  [{'question': '(가)와 (나)에 대한 설명으로 가장 적절한 것은?', ...  \n",
            "2     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "3     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "4     1  [{'question': '윗글에 대한 설명으로 가장 적절한 것은?', 'choic...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def count_probles_pro(problems):\n",
        "    question_count = 0\n",
        "    choices_count = 0\n",
        "    answer_count = 0\n",
        "    score_count = 0\n",
        "\n",
        "    count = 0\n",
        "    for problem in problems:\n",
        "        count += 1\n",
        "        print(f\"count: {count}\")\n",
        "        print(problem)\n",
        "        print()\n",
        "        if 'question' in problem:\n",
        "            question_count += 1\n",
        "        if 'question' in problem:\n",
        "            question = problem['question']\n",
        "            print(f\"question: {question}\")\n",
        "        if 'choices' in problem:\n",
        "            choices_count += 1\n",
        "        if 'score' in problem:\n",
        "            score_count += 1\n",
        "        if 'answer' in problem:\n",
        "            answer_count += 1\n",
        "\n",
        "    return question_count,choices_count,answer_count,score_count\n",
        "\n",
        "question_count,choices_count,answer_count,score_count = count_probles_pro(dftest['problems'][0])\n",
        "print(f\"question:{question_count}, choices_count:{choices_count},answer_count: {answer_count}, score_count: {score_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSdD4pzZ64m-",
        "outputId": "d9737feb-7e08-4381-e2b7-847109bdf8ec"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 1\n",
            "{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.', '독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다'], 'answer': 4, 'score': 2}\n",
            "\n",
            "question: 윗글의 내용과 일치하지 않는 것은?\n",
            "count: 2\n",
            "{'question': '다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?', 'question_plus': \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 <합창>이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) <합창>을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\", 'choices': ['ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.', 'ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.', 'ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.', 'ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.', 'ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.'], 'answer': 5, 'score': 3}\n",
            "\n",
            "question: 다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?\n",
            "count: 3\n",
            "{'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?', 'choices': ['스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.', '독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.', '개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.', '자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.', '오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.'], 'answer': 1, 'score': 2}\n",
            "\n",
            "question: 윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?\n",
            "question:3, choices_count:3,answer_count: 3, score_count: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(df['problems'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x6fd1XBJ8gVQ",
        "outputId": "4ec3adf4-a57b-49cf-8ebd-88290de56ada"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_answer_and_score(problems):\n",
        "    for problem in problems:\n",
        "        if 'answer' in problem:\n",
        "            del problem['answer']  # 移除 answer\n",
        "        if 'score' in problem:\n",
        "            del problem['score']  # 移除 score\n",
        "    return problems\n",
        "\n",
        "# 对 df 的 problems 列应用函数\n",
        "dftest['problems'] = dftest['problems'].apply(remove_answer_and_score)\n",
        "\n",
        "# 检查结果\n",
        "print(dftest.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tarLukXoyWxT",
        "outputId": "93c96b09-6cd9-4555-d089-cbb74296ee20"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                   id                                          paragraph  \\\n",
            "0    2023_11_KICE_1-3  사람들이 지속적으로 책을 읽는 이유 중 하나는 즐거움이다. 독서의 즐거움에는 여러 ...   \n",
            "1    2023_11_KICE_4-9  (가)[A](중국에서 비롯된 유서(類書)는 고금의 서적에서 자료를 수집하고 항목별로...   \n",
            "2  2023_11_KICE_10-13  법령의 조문은 대개 ‘A에 해당하면 B를 해야 한다.’처럼 요건과효과로 구성된 조건...   \n",
            "3  2023_11_KICE_14-17  하루에 필요한 에너지의 양은 하루 동안의 총 열량 소모량인 대사량으로 구한다. 그중...   \n",
            "4  2023_11_KICE_18-21  혼례를 마친 후 최척이 아내와 함께 장모를 모시고 집으로 돌아오매 하인들이 기뻐했다...   \n",
            "\n",
            "   type                                           problems  \n",
            "0     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "1     0  [{'question': '(가)와 (나)에 대한 설명으로 가장 적절한 것은?', ...  \n",
            "2     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "3     0  [{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices'...  \n",
            "4     1  [{'question': '윗글에 대한 설명으로 가장 적절한 것은?', 'choic...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_count,choices_count,answer_count,score_count = count_probles_pro(dftest['problems'][0])\n",
        "print(f\"question:{question_count}, choices_count:{choices_count},answer_count: {answer_count}, score_count: {score_count}\")"
      ],
      "metadata": {
        "id": "WVOkC8WbX4H-",
        "outputId": "b9750157-d03e-4975-a81c-605ac3dccf10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "count: 1\n",
            "{'question': '윗글의 내용과 일치하지 않는 것은?', 'choices': ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.', '독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다']}\n",
            "\n",
            "question: 윗글의 내용과 일치하지 않는 것은?\n",
            "count: 2\n",
            "{'question': '다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?', 'question_plus': \"ⓐ('음악 시간에 들었던 베토벤의 교향곡 <합창>이 위대한 작품인 이유는 무엇일까?'하는 생각)에, 베토벤에 대한 책을 빌렸다. 책에서는 기약만으로 구성됐던 교향곡에 성악을 결합헤 개성을 드러냈다는 점에서 ⓑ(이 곡이 낭만주의 음악의 특징을 보여 준다고 했다.) <합창>을 해설한 부분에 이어, 베토벤의 생애에 관한 뒷부분도 읽었는데, ⓒ(이 내용들을 종합해, 절망적 상황에서도 열정적으로 자신이 좋아하는 일을 했기에 교향곡 구성의 새로움을 보여 준 명작이 탄생했음을 알게 됐다.) 이후 ⓓ(내가 진정으로 좋아하는 일이 무엇인지 나에게 묻게 되었다.) ⓔ(글 쓰는 일에서 가장 큰 행복을 느꼈던 나를 발견)할 수 있었고, 나도 어떤 상황에서든 좋아하는 일을 계속해야겠다고 생각했다.\", 'choices': ['ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.', 'ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.', 'ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.', 'ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.', 'ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.']}\n",
            "\n",
            "question: 다음은 학생이 독서 후 작성한 글의 일부이다. [A]를 바탕으로 ⓐ～ⓔ를 이해한 내용으로 가장 적절한 것은?\n",
            "count: 3\n",
            "{'question': '윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?', 'choices': ['스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.', '독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.', '개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.', '자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.', '오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.']}\n",
            "\n",
            "question: 윗글을 읽고 ㉠에 대해 보인 반응으로 적절하지 않은 것은?\n",
            "question:3, choices_count:3,answer_count: 0, score_count: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def question_deliver(dftest):\n",
        "    count = 0\n",
        "\n",
        "    for item in dftest:\n",
        "      count +=1\n",
        "      print(\"id: \\n\",item['id'])\n",
        "      paragraph = item['paragraph']\n",
        "      if count > 0: break\n",
        "    return paragraph\n"
      ],
      "metadata": {
        "id": "moNK0drGZvNM"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qData= question_deliver(dftest)"
      ],
      "metadata": {
        "id": "bINbqpyuZ_U6",
        "outputId": "cdddf2f6-9e6f-4ba8-e24d-01a34a06f44d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        }
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "string indices must be integers",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-139-425377686725>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqData\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mquestion_deliver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdftest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-138-7631a139cc20>\u001b[0m in \u001b[0;36mquestion_deliver\u001b[0;34m(dftest)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdftest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m       \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"id: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mparagraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'paragraph'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"paragraph: \\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparagraph\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: string indices must be integers"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(qData[0])"
      ],
      "metadata": {
        "id": "Xcys5GNkaI9Y",
        "outputId": "33142255-ca9b-4041-9ad1-eb4a8243eb26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t4_iPGh_aI12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CY_HgIwaIex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing_extensions import Counter\n",
        "# 加载 JSON 数据\n",
        "\n",
        "total_score = 0\n",
        "count = 0\n",
        "for item in data:\n",
        "    count +=1\n",
        "    print(item)\n",
        "    if count > 5: break"
      ],
      "metadata": {
        "id": "Pcq6PW6L_9pq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for item in data:\n",
        "    count +=1\n",
        "    print(\"id: \\n\",item['id'])\n",
        "    paragraph = item['paragraph']\n",
        "    print(\"paragraph: \\n\",paragraph[:20],\"...\")\n",
        "\n",
        "    for problem in item['problems']:\n",
        "      question = problem['question']\n",
        "      choices = problem['choices']\n",
        "      print(\"---- question: \\n\",question[:20],\"...\")\n",
        "      print(\"-------- choices: \\n\",choices[:20],\"...\",\"\\n\\n\")\n",
        "    if count > 0: break"
      ],
      "metadata": {
        "id": "KHNErixzGOgb",
        "outputId": "fc739725-6d0a-4b0f-a5af-0ac21fff725f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: \n",
            " 2023_11_KICE_1-3\n",
            "paragraph: \n",
            " 사람들이 지속적으로 책을 읽는 이유  ...\n",
            "---- question: \n",
            " 윗글의 내용과 일치하지 않는 것은? ...\n",
            "-------- choices: \n",
            " ['같은 책을 읽은 독자라도 서로 다른 의미를 구성할 수 있다.', '다른 독자와의 소통은 독자가 인식의 폭을 확장하도록 돕는다', '독자는 직접 경험해 보지 못했던 다양한 삶을 책의 필자를 매개로 접할 수 있다.', '독자의 배경지식, 관점, 읽기 환경, 과제는 독자의 의미 구성에 영향을 주는 독자 요인이다.', '독자는 책을 읽을 때 자신이 속한 사회나 시대의 영향을 받으며 필자와 간접적으로 대화한다'] ... \n",
            "\n",
            "\n",
            "---- question: \n",
            " 다음은 학생이 독서 후 작성한 글의  ...\n",
            "-------- choices: \n",
            " ['ⓐ와 ⓑ에는 모두 ‘독자 자신에게서 답을 찾는 질문’이 나타난다.', 'ⓒ와 ⓓ에는 모두 ‘책에 명시된 내용’에서 질문의 답을 찾아내는 모습이 나타난다.', 'ⓐ에는 ‘책에서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.', 'ⓑ에는 ‘책에서 답을 찾는 질문’이, ⓒ에는 그에 대한 답을 ‘책의 내용들을 관계 지으며’ 찾아내는 모습이 나타난다.', 'ⓓ에는 ‘독자 자신에게서 답을 찾는 질문’이, ⓔ에는 그에 대한 답을 ‘독자의 경험’에서 찾아내는 모습이 나타난다.'] ... \n",
            "\n",
            "\n",
            "---- question: \n",
            " 윗글을 읽고 ㉠에 대해 보인 반응으로 ...\n",
            "-------- choices: \n",
            " ['스스로 독서 계획을 세우고 자신에게 필요한 책을 찾아 개인적으로 읽는 과정에서 경험할 수 있겠군.', '독서 모임에서 서로 다른 관점을 확인하고 자신의 관점을 조정하는 과정에서 경험할 수 있겠군.', '개인적으로 형성한 의미를, 독서 동아리를 통해 심화하는 과정에서 경험할 수 있겠군.', '자신의 독서 경험을 담은 콘텐츠를 생산하고 공유하는 과정에서 경험할 수 있겠군.', '오프라인뿐 아니라 온라인 공간에서 해석을 나누는 과정에서도 경험할 수 있겠군.'] ... \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "basic_prompt = PromptTemplate.from_template(\n",
        "        \"\"\"\n",
        "        국어 시험 문제를 푸는 똑똑한 학생으로서 다음 문제의 답을 구하세요.\n",
        "        지문을 읽고, 질문에 대한 답을 1부터 5까지의 선택지 중에 한 개만 골라서 대답해야 합니다.\n",
        "\n",
        "        지문 :\n",
        "        {paragraph}\n",
        "\n",
        "        질문 :\n",
        "        {question}\n",
        "\n",
        "        선택지 :\n",
        "        1번 - {choices_1}\n",
        "        2번 - {choices_2}\n",
        "        3번 - {choices_3}\n",
        "        4번 - {choices_4}\n",
        "        5번 - {choices_5}\n",
        "\n",
        "        1번, 2번, 3번, 4번, 5번 중에 하나를 정답으로 고르세요.\n",
        "\n",
        "        아래 포멧데로 결과를 주세요\n",
        "        {paragraph[i]:question[i]:{choices[i],answer[i],scroe}}\n",
        "\n",
        "        \"\"\"\n",
        "    )"
      ],
      "metadata": {
        "id": "0nMQP--gfrjJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(basic_prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhq4-JkJgD1y",
        "outputId": "4013caef-c3c8-48b0-e420-e9130394de03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_variables=['choices_1', 'choices_2', 'choices_3', 'choices_4', 'choices_5', 'paragraph', 'question'] input_types={} partial_variables={} template='\\n        국어 시험 문제를 푸는 똑똑한 학생으로서 다음 문제의 답을 구하세요.\\n        지문을 읽고, 질문에 대한 답을 1부터 5까지의 선택지 중에 한 개만 골라서 대답해야 합니다.\\n        \\n        지문 : \\n        {paragraph}\\n        \\n        질문 : \\n        {question}\\n        \\n        선택지 :\\n        1번 - {choices_1}\\n        2번 - {choices_2}\\n        3번 - {choices_3}\\n        4번 - {choices_4}\\n        5번 - {choices_5}\\n        \\n        1번, 2번, 3번, 4번, 5번 중에 하나를 정답으로 고르세요. 정답 :\\n        '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "message=[{\"role\": \"assistant\", \"content\": basic_prompt}, {\"role\": \"user\", \"content\": df.head().to_string()}]\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    messages=message,\n",
        "    n=1,\n",
        "    max_tokens=max_tokens,\n",
        "    temperature=0.0,\n",
        "    frequency_penalty=frequency_penalty\n",
        ")\n",
        "print(response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "ke77YQcotDuX",
        "outputId": "4286e85e-f032-4183-cf07-edd222b18bb2"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content': expected one of a string or array of objects, but got an object instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content', 'code': 'invalid_type'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-8e98a7b0a24e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"assistant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbasic_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m response = openai.chat.completions.create(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmessages\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/chat/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    857\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    858\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1279\u001b[0m         )\n\u001b[0;32m-> 1280\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1281\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1282\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    955\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    956\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    958\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1044\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mremaining_retries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m                 \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m                 return self._retry_request(\n\u001b[0m\u001b[1;32m   1047\u001b[0m                     \u001b[0minput_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m                     \u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_retry_request\u001b[0;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1095\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m   1096\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1059\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1060\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1061\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1063\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"Invalid type for 'messages[0].content': expected one of a string or array of objects, but got an object instead.\", 'type': 'invalid_request_error', 'param': 'messages[0].content', 'code': 'invalid_type'}}"
          ]
        }
      ]
    }
  ]
}